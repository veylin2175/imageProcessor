# Image Processor API

Проект **Image Processor API** — это асинхронный микросервис для обработки изображений, разработанный на Go. Он предоставляет RESTful API для загрузки изображений и управления ими, используя **Apache Kafka** для выполнения ресурсоёмких задач обработки в фоновом режиме.

## Основные особенности

- **RESTful API**: Предоставляет интуитивно понятный HTTP-интерфейс для загрузки, получения статуса, просмотра и удаления изображений.
- **Асинхронная обработка**: Задачи по изменению размеров, добавлению водяных знаков и созданию миниатюр отправляются в очередь Kafka, что позволяет API-серверу быстро отвечать на запросы, не блокируя работу.
- **Гибкое хранение**: Исходные и обработанные изображения сохраняются на диске, в то время как все метаданные (ID, статус, пути) хранятся в надёжной базе данных **PostgreSQL**.
- **Интеграционное тестирование**: Проект включает в себя полноценный набор тестов, которые проверяют весь жизненный цикл обработки изображения в изолированной тестовой среде.
- **Документация**: Автоматически генерируемая документация **Swagger UI** делает API-сервис понятным и удобным для использования.

-----

## Архитектура

Проект развёртывается с помощью **Docker Compose**, который управляет несколькими связанными сервисами:

- **`image-processor`**: Основное приложение на Go, которое обрабатывает HTTP-запросы и взаимодействует с Kafka и PostgreSQL.
- **`image-worker`**: Асинхронный Go-сервис, который потребляет сообщения из Kafka, выполняет реальную обработку изображений (изменение размера, добавление водяных знаков) и обновляет статус в базе данных.
- **`database`**: Контейнер **PostgreSQL**, служащий основным хранилищем метаданных.
- **`kafka`**: Брокер сообщений **Apache Kafka**, обеспечивающий надёжную очередь задач.
- **`zookeeper`**: Сервис-координатор, необходимый для работы Kafka.
- **`migrations`**: Контейнер с миграциями базы данных, предоставляющий удобную координацию и взаимодействие с таблицами.


-----

## Начало работы

### Зависимости

Для запуска проекта вам потребуется:

- **Docker** и **Docker Compose**: Установите их, следуя инструкциям на [официальном сайте Docker](https://docs.docker.com/compose/install/).
- **Go 1.22+**: Необходим для локальной разработки, запуска тестов и генерации документации.

### Запуск проекта

1.  Клонируйте репозиторий:

    ```bash
    git clone https://github.com/veylin2175/imageProcessor
    cd imageProcessor
    ```

2.  Запустите все сервисы с помощью Docker Compose:

    ```bash
    docker-compose up -d --build
    ```

    - `up`: Запускает контейнеры, определённые в `docker-compose.yml`.
    - `-d`: Запускает контейнеры в фоновом режиме.
    - `--build`: Принудительно пересобирает образ `image-processor` из исходного кода, что гарантирует использование самой свежей версии приложения.

После запуска, API будет доступно по адресу `http://localhost:8075`.

-----

## API Endpoints

Полная документация API доступна через **Swagger UI**, что позволяет тестировать эндпоинты прямо из браузера.

- **Swagger UI**: `http://localhost:8075/swagger/index.html`

### Ключевые эндпоинты

- **`POST /upload`**:

    - **Описание**: Загружает изображение в формате `multipart/form-data`. После сохранения файла, в Kafka отправляется сообщение, и запускается асинхронная обработка.
    - **Параметры**: `image` (файл).
    - **Ответ**: JSON, содержащий `image_id` и статус `OK`.

- **`GET /image/{id}`**:

    - **Описание**: Получает полную информацию об изображении по его уникальному ID, включая текущий статус обработки и пути к обработанным файлам.
    - **Параметры**: `id` в пути (`UUID`).
    - **Ответ**: JSON с метаданными изображения.

- **`GET /processed/{path}`**:

    - **Описание**: Сервирует обработанное изображение по его относительному пути, например, `/processed/image_id_resized.jpg`.
    - **Параметры**: `path` (полный путь к файлу).
    - **Ответ**: Файл изображения.

- **`DELETE /image/{id}`**:

    - **Описание**: Удаляет изображение, его обработанные версии и все связанные с ним метаданные из базы данных.
    - **Параметры**: `id` в пути (`UUID`).
    - **Ответ**: Статус операции.

-----

## Тестирование

Проект включает набор **интеграционных тестов**, которые используют отдельный `docker-compose-test.yml` для создания изолированной среды с тестовой базой данных и Kafka.

Для запуска тестов:

1.  Убедитесь, что основные контейнеры не запущены:

    ```bash
    docker-compose down
    ```

2.  Выполните команду `docker-compose -f docker-compose-test.yml up -d --build` в корневой директории проекта. Она автоматически запустит тестовые контейнеры:

    ```bash
    docker-compose -f docker-compose-test.yml up -d --build
    ```

3.  Выполните команду `go test` в корневой директории проекта. Она автоматически запустит и выполнит все тесты:

    ```bash
    go test ./...
    ```

4.  После завершения тестов, убедитесь, что тестовая среда полностью очищена:

    ```bash
    docker-compose -f docker-compose-test.yml down -v
    ```

    Флаг `-v` удаляет тома Docker, очищая тестовые данные, что важно для поддержания чистоты среды.

-----

## Разработка и конфигурация

- **Генерация Swagger**: Для обновления документации API после внесения изменений в код выполните:
  ```bash
  swag init -dir ./ -g cmd/image-processor/main.go
  ```
- **Конфигурация**: Настройки проекта хранятся в файле конфигурации `config/local.example.yml`. Создайте в той же директории свой файл `local.yml` и заполните его по образцу, изменяя некоторые данные под свои. Здесь вы можете изменить параметры подключения к базе данных, Kafka и другие настройки.
